2023-09-12 17:19:00.853095: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-09-12 17:19:03.428236: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30137 MB memory:  -> device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:3b:00.0, compute capability: 7.0
SCRIPT INITIATED
INI
CHECKPOINT
182766    [2.4097, 0.7755, 2.6289, 0.5484, 1.3214, 0.549...
159777    [2.4574, 0.6275, 2.1196, 0.4437, 1.0903, 0.441...
112750    [2.4775, 0.6335, 2.1037, 0.4479, 1.1097, 0.445...
100981    [2.5123, 0.7222, 2.5504, 0.5107, 1.283, 0.5085...
88496     [2.3979, 0.6322, 2.0621, 0.447, 1.0719, 0.4446...
                                ...                        
89912     [2.365, 0.6396, 2.0655, 0.4523, 1.0697, 0.4495...
34106     [2.4315, 0.7626, 2.5761, 0.5393, 1.3112, 0.536...
146375    [2.4266, 0.7826, 2.5878, 0.5534, 1.3429, 0.552...
39708     [2.3653, 0.7558, 2.4607, 0.5344, 1.2641, 0.533...
90162     [2.3911, 0.7271, 2.4074, 0.5141, 1.2293, 0.511...
Name: X, Length: 38195, dtype: object
182766    [3]
159777    [0]
112750    [0]
100981    [2]
88496     [0]
         ... 
89912     [0]
34106     [1]
146375    [1]
39708     [1]
90162     [4]
Name: y, Length: 38195, dtype: object
#ASSIGNAMEMNT
X_train [[ 2.4097  0.7755  2.6289 ...  0.142   2.8542 73.0099]
 [ 2.4574  0.6275  2.1196 ...  0.1028  2.7963 73.776 ]
 [ 2.4775  0.6335  2.1037 ...  0.1036  2.8924 73.4715]
 ...
 [ 2.5475  0.714   2.5661 ...  0.105   2.8734 73.4434]
 [ 2.3215  0.7702  2.5266 ...  0.1058  2.8949 72.0677]
 [ 2.4369  0.6183  2.0322 ...  0.1012  2.8879 73.7896]]
X_test         S1_CrestFactor_g~g  S1_DerivedPeak_g  ...  S2_Kurtosis_g~g  S1_temp
95489               2.4475            0.7662  ...           2.9285  73.4051
77245               2.5196            0.6198  ...           2.9455  73.6543
6886                2.5483            0.6308  ...           2.8807  72.8396
91821               2.4040            0.7620  ...           2.8340  72.8426
91308               2.4910            0.7602  ...           2.8173  72.7376
...                    ...               ...  ...              ...      ...
2462                2.3696            0.6370  ...           2.7123  72.6504
214975              2.3406            0.7863  ...           2.7075  73.2147
179171              2.5302            0.7095  ...           2.9358  73.4898
148740              2.3707            0.7642  ...           3.0892  73.6162
123127              2.3926            0.7836  ...           2.9755  73.2097

[47745 rows x 15 columns]
X_vals [[ 2.4031  0.7687  2.5914 ...  0.1044  2.8615 73.292 ]
 [ 2.3194  0.6333  2.0652 ...  0.1026  2.8106 73.1925]
 [ 2.4848  0.7207  2.5221 ...  0.1053  2.842  72.9583]
 ...
 [ 2.4266  0.7826  2.5878 ...  0.1079  2.9452 72.3689]
 [ 2.3653  0.7558  2.4607 ...  0.1044  2.9781 73.575 ]
 [ 2.3911  0.7271  2.4074 ...  0.1703  2.7473 73.2807]]
y_test Classes {0: 15849, 1: 14627, 2: 7269, 3: 5946, 4: 4054}
y_train Classes {0: 4898, 1: 6704, 2: 3497, 3: 12439, 4: 1108}
y_vals Classes {0: 2858, 1: 3934, 2: 2191, 4: 566}
(38195, 2)
(38195,)
(38195,)
(28646, 15)
(9549, 15)
(47745, 15)
logs/fit/20230912-171903
Epoch 1/30
2023-09-12 17:19:04.874051: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd670377ec0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-09-12 17:19:04.874097: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0
2023-09-12 17:19:04.879781: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-09-12 17:19:04.895956: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600
2023-09-12 17:19:05.014378: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
  1/896 [..............................] - ETA: 19:52 - loss: 1.6405 - accuracy: 0.2812 23/896 [..............................] - ETA: 2s - loss: 1.8219 - accuracy: 0.3030    46/896 [>.............................] - ETA: 1s - loss: 1.8403 - accuracy: 0.3084 69/896 [=>............................] - ETA: 1s - loss: 1.8348 - accuracy: 0.3057 92/896 [==>...........................] - ETA: 1s - loss: 1.8450 - accuracy: 0.2959115/896 [==>...........................] - ETA: 1s - loss: 1.8491 - accuracy: 0.2965138/896 [===>..........................] - ETA: 1s - loss: 1.8538 - accuracy: 0.2985161/896 [====>.........................] - ETA: 1s - loss: 1.8564 - accuracy: 0.2989185/896 [=====>........................] - ETA: 1s - loss: 1.8564 - accuracy: 0.3007209/896 [=====>........................] - ETA: 1s - loss: 1.8556 - accuracy: 0.3032232/896 [======>.......................] - ETA: 1s - loss: 1.8551 - accuracy: 0.3021255/896 [=======>......................] - ETA: 1s - loss: 1.8562 - accuracy: 0.2994278/896 [========>.....................] - ETA: 1s - loss: 1.8548 - accuracy: 0.2984301/896 [=========>....................] - ETA: 1s - loss: 1.8549 - accuracy: 0.2991324/896 [=========>....................] - ETA: 1s - loss: 1.8515 - accuracy: 0.3023346/896 [==========>...................] - ETA: 1s - loss: 1.8484 - accuracy: 0.3027368/896 [===========>..................] - ETA: 1s - loss: 1.8489 - accuracy: 0.3012391/896 [============>.................] - ETA: 1s - loss: 1.8488 - accuracy: 0.3010414/896 [============>.................] - ETA: 1s - loss: 1.8496 - accuracy: 0.3003437/896 [=============>................] - ETA: 1s - loss: 1.8509 - accuracy: 0.2991460/896 [==============>...............] - ETA: 0s - loss: 1.8491 - accuracy: 0.3003482/896 [===============>..............] - ETA: 0s - loss: 1.8484 - accuracy: 0.3004504/896 [===============>..............] - ETA: 0s - loss: 1.8472 - accuracy: 0.3015527/896 [================>.............] - ETA: 0s - loss: 1.8476 - accuracy: 0.3013549/896 [=================>............] - ETA: 0s - loss: 1.8479 - accuracy: 0.3015572/896 [==================>...........] - ETA: 0s - loss: 1.8478 - accuracy: 0.3024594/896 [==================>...........] - ETA: 0s - loss: 1.8470 - accuracy: 0.3025618/896 [===================>..........] - ETA: 0s - loss: 1.8464 - accuracy: 0.3025641/896 [====================>.........] - ETA: 0s - loss: 1.8471 - accuracy: 0.3031665/896 [=====================>........] - ETA: 0s - loss: 1.8478 - accuracy: 0.3029689/896 [======================>.......] - ETA: 0s - loss: 1.8487 - accuracy: 0.3032712/896 [======================>.......] - ETA: 0s - loss: 1.8485 - accuracy: 0.3038735/896 [=======================>......] - ETA: 0s - loss: 1.8497 - accuracy: 0.3036759/896 [========================>.....] - ETA: 0s - loss: 1.8496 - accuracy: 0.3040782/896 [=========================>....] - ETA: 0s - loss: 1.8491 - accuracy: 0.3040805/896 [=========================>....] - ETA: 0s - loss: 1.8477 - accuracy: 0.3043828/896 [==========================>...] - ETA: 0s - loss: 1.8478 - accuracy: 0.3040851/896 [===========================>..] - ETA: 0s - loss: 1.8473 - accuracy: 0.3042874/896 [============================>.] - ETA: 0s - loss: 1.8475 - accuracy: 0.3041896/896 [==============================] - ETA: 0s - loss: 1.8474 - accuracy: 0.3044Traceback (most recent call last):
  File "fl_testbed/version2/client/independent.py", line 2248, in <module>
    independent.modeling_1()
  File "fl_testbed/version2/client/independent.py", line 1300, in modeling_1
    history=self.model.fit(X_train, y_train,epochs=self.epochs,batch_size=32,validation_data=(X_vals,y_vals) ,verbose=1,callbacks=[tensorboard_callback,lr,es],)
  File "/usr/local/lib/python3.8/dist-packages/keras/src/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/tmp/__autograph_generated_file3isp4knl.py", line 15, in tf__test_function
    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)
ValueError: in user code:

    File "/usr/local/lib/python3.8/dist-packages/keras/src/engine/training.py", line 1972, in test_function  *
        return step_function(self, iterator)
    File "/usr/local/lib/python3.8/dist-packages/keras/src/engine/training.py", line 1956, in step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "/usr/local/lib/python3.8/dist-packages/keras/src/engine/training.py", line 1944, in run_step  **
        outputs = model.test_step(data)
    File "/usr/local/lib/python3.8/dist-packages/keras/src/engine/training.py", line 1852, in test_step
        self.compute_loss(x, y, y_pred, sample_weight)
    File "/usr/local/lib/python3.8/dist-packages/keras/src/engine/training.py", line 1139, in compute_loss
        return self.compiled_loss(
    File "/usr/local/lib/python3.8/dist-packages/keras/src/engine/compile_utils.py", line 265, in __call__
        loss_value = loss_obj(y_t, y_p, sample_weight=sw)
    File "/usr/local/lib/python3.8/dist-packages/keras/src/losses.py", line 142, in __call__
        losses = call_fn(y_true, y_pred)
    File "/usr/local/lib/python3.8/dist-packages/keras/src/losses.py", line 268, in call  **
        return ag_fn(y_true, y_pred, **self._fn_kwargs)
    File "/usr/local/lib/python3.8/dist-packages/keras/src/losses.py", line 2122, in categorical_crossentropy
        return backend.categorical_crossentropy(
    File "/usr/local/lib/python3.8/dist-packages/keras/src/backend.py", line 5560, in categorical_crossentropy
        target.shape.assert_is_compatible_with(output.shape)

    ValueError: Shapes (None, 4) and (None, 5) are incompatible

