2023-12-14 17:57:03.997648: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-12-14 17:57:15.712131: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31141 MB memory:  -> device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:3b:00.0, compute capability: 7.0
2023-12-14 17:57:15.738822: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31141 MB memory:  -> device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:3b:00.0, compute capability: 7.0
SCRIPT INITIATED
INI
MODE 3
['S1_CrestFactor_g~g', 'S1_DerivedPeak_g', 'S1_Peak~Peak_g', 'S1_RMS_g', 'S1_TruePeak_g', 'S1_HighFrequency_grms', 'S1_Kurtosis_g~g', 'S2_CrestFactor_g~g', 'S2_DerivedPeak_g', 'S2_Peak~Peak_g', 'S2_RMS_g', 'S2_TruePeak_g', 'S2_HighFrequency_grms', 'S2_Kurtosis_g~g']
0         2009308.0
1         2009307.0
2         2009306.0
3         2009305.0
4         2009304.0
            ...    
238239        499.0
238240        498.0
238241        497.0
238242        496.0
238243        495.0
Name: rul, Length: 238244, dtype: float64
range(0, 238244)
Index(['S1_CrestFactor_g~g', 'S1_DerivedPeak_g', 'S1_Peak~Peak_g', 'S1_RMS_g',
       'S1_TruePeak_g', 'S1_HighFrequency_grms', 'S1_Kurtosis_g~g',
       'S2_CrestFactor_g~g', 'S2_DerivedPeak_g', 'S2_Peak~Peak_g', 'S2_RMS_g',
       'S2_TruePeak_g', 'S2_HighFrequency_grms', 'S2_Kurtosis_g~g', 'S1_temp',
       'status'],
      dtype='object')
rul
TRAIN_INPUT CHECK
[[[ 2.3598  0.7699  2.5188 ...  3.1269 73.4159  1.    ]
  [ 2.4088  0.7702  2.5423 ...  3.1985 73.4812  1.    ]
  [ 2.3791  0.7711  2.5447 ...  3.0902 73.4887  1.    ]
  ...
  [ 2.4069  0.7636  2.5006 ...  2.9618 73.4228  1.    ]
  [ 2.4042  0.7631  2.5298 ...  2.9463 73.3773  1.    ]
  [ 2.3229  0.7615  2.4664 ...  3.0051 73.4308  1.    ]]

 [[ 2.5739  0.6234  2.1101 ...  2.7508 73.2962  0.    ]
  [ 2.3869  0.6207  2.0906 ...  2.8185 73.3225  0.    ]
  [ 2.3489  0.6232  1.9858 ...  2.7852 73.3151  0.    ]
  ...
  [ 2.4395  0.6211  2.0731 ...  2.803  73.3833  0.    ]
  [ 2.4042  0.6231  2.0319 ...  2.8674 73.3603  0.    ]
  [ 2.3351  0.6249  2.0271 ...  2.7474 73.3677  0.    ]]

 [[ 2.3697  0.7624  2.5237 ...  2.8377 73.2838  1.    ]
  [ 2.3798  0.762   2.5233 ...  3.0007 73.2609  1.    ]
  [ 2.3596  0.7621  2.5224 ...  2.8795 73.2609  1.    ]
  ...
  [ 2.3967  0.7571  2.543  ...  3.0694 73.579   1.    ]
  [ 2.4538  0.7573  2.5376 ...  3.1696 73.5501  1.    ]
  [ 2.3576  0.7565  2.4672 ...  2.8643 73.6267  1.    ]]

 ...

 [[ 2.4804  0.7285  2.5083 ...  2.998  73.1399  2.    ]
  [ 2.5239  0.7274  2.5795 ...  2.9703 73.1753  2.    ]
  [ 2.4946  0.728   2.5473 ...  2.9777 73.1298  2.    ]
  ...
  [ 2.5002  0.7236  2.5295 ...  3.0273 73.1502  2.    ]
  [ 2.5056  0.7257  2.5373 ...  2.8628 73.1013  2.    ]
  [ 2.4832  0.7259  2.543  ...  2.9295 73.0743  2.    ]]

 [[ 2.4177  0.6199  2.0724 ...  2.9715 71.898   0.    ]
  [ 2.4366  0.6189  2.0794 ...  2.9353 71.9098  0.    ]
  [ 2.3012  0.6168  1.984  ...  2.8917 71.8903  0.    ]
  ...
  [ 2.4167  0.6138  2.0487 ...  3.0337 71.8225  0.    ]
  [ 2.5354  0.6177  2.1136 ...  2.8766 71.7992  0.    ]
  [ 2.4745  0.6179  2.0384 ...  2.9238 71.8162  0.    ]]

 [[ 2.5183  0.7635  2.5936 ...  3.0372 73.3915  1.    ]
  [ 2.3257  0.7608  2.4831 ...  2.8293 73.4153  1.    ]
  [ 2.3702  0.763   2.5354 ...  3.0792 73.4506  1.    ]
  ...
  [ 2.5475  0.7586  2.5999 ...  2.7971 73.3722  1.    ]
  [ 2.3402  0.7606  2.4576 ...  2.9411 73.432   1.    ]
  [ 2.4175  0.7628  2.5464 ...  2.8358 73.4637  1.    ]]]
(6691, 80, 16)
(6691, 80, 15)
train_out
(6691, 1)
test_out
(2974, 1)
vals_out
[[1303890.]
 [1208448.]
 [1314493.]
 ...
 [  11975.]
 [1482764.]
 [1387792.]]
(2231, 1)
[[0.64886963]
 [0.60135279]
 [0.65414845]
 ...
 [0.00567561]
 [0.73792401]
 [0.69064116]]
(2231, 1)
(6691, 80, 15)
(2974, 80, 15)
(2231, 80, 15)
logs/fit/20231214-175715
Epoch 1/100
2023-12-14 17:57:18.300948: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600
2023-12-14 17:57:18.565956: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f61e0681cf0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-12-14 17:57:18.566003: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0
2023-12-14 17:57:18.571559: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-12-14 17:57:18.675455: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
210/210 - 6s - loss: 0.3159 - mse: 0.8007 - mae: 0.6904 - val_loss: 0.2266 - val_mse: 0.4580 - val_mae: 0.5883 - 6s/epoch - 29ms/step
Epoch 2/100
210/210 - 1s - loss: 0.2008 - mse: 0.4055 - mae: 0.5434 - val_loss: 0.1626 - val_mse: 0.3272 - val_mae: 0.4765 - 1s/epoch - 7ms/step
Epoch 3/100
210/210 - 1s - loss: 0.1205 - mse: 0.2420 - mae: 0.3990 - val_loss: 0.0850 - val_mse: 0.1701 - val_mae: 0.3346 - 1s/epoch - 6ms/step
Epoch 4/100
210/210 - 1s - loss: 0.0680 - mse: 0.1361 - mae: 0.2925 - val_loss: 0.0575 - val_mse: 0.1150 - val_mae: 0.2681 - 1s/epoch - 7ms/step
Epoch 5/100
210/210 - 1s - loss: 0.0537 - mse: 0.1073 - mae: 0.2579 - val_loss: 0.0518 - val_mse: 0.1036 - val_mae: 0.2555 - 1s/epoch - 6ms/step
Epoch 6/100
210/210 - 1s - loss: 0.0497 - mse: 0.0994 - mae: 0.2466 - val_loss: 0.0489 - val_mse: 0.0978 - val_mae: 0.2441 - 1s/epoch - 7ms/step
Epoch 7/100
210/210 - 1s - loss: 0.0476 - mse: 0.0953 - mae: 0.2413 - val_loss: 0.0477 - val_mse: 0.0954 - val_mae: 0.2333 - 1s/epoch - 6ms/step
Epoch 8/100
210/210 - 1s - loss: 0.0457 - mse: 0.0915 - mae: 0.2360 - val_loss: 0.0448 - val_mse: 0.0895 - val_mae: 0.2280 - 1s/epoch - 7ms/step
Epoch 9/100
210/210 - 1s - loss: 0.0436 - mse: 0.0871 - mae: 0.2311 - val_loss: 0.0424 - val_mse: 0.0847 - val_mae: 0.2340 - 1s/epoch - 7ms/step
Epoch 10/100
210/210 - 1s - loss: 0.0415 - mse: 0.0829 - mae: 0.2265 - val_loss: 0.0397 - val_mse: 0.0795 - val_mae: 0.2238 - 1s/epoch - 7ms/step
Epoch 11/100
210/210 - 1s - loss: 0.0398 - mse: 0.0796 - mae: 0.2232 - val_loss: 0.0384 - val_mse: 0.0767 - val_mae: 0.2168 - 1s/epoch - 7ms/step
Epoch 12/100
210/210 - 1s - loss: 0.0384 - mse: 0.0768 - mae: 0.2189 - val_loss: 0.0372 - val_mse: 0.0743 - val_mae: 0.2189 - 1s/epoch - 7ms/step
Epoch 13/100
210/210 - 1s - loss: 0.0371 - mse: 0.0741 - mae: 0.2157 - val_loss: 0.0356 - val_mse: 0.0712 - val_mae: 0.2102 - 1s/epoch - 7ms/step
Epoch 14/100
210/210 - 1s - loss: 0.0353 - mse: 0.0706 - mae: 0.2109 - val_loss: 0.0346 - val_mse: 0.0692 - val_mae: 0.2054 - 1s/epoch - 7ms/step
Epoch 15/100
210/210 - 1s - loss: 0.0336 - mse: 0.0672 - mae: 0.2061 - val_loss: 0.0359 - val_mse: 0.0718 - val_mae: 0.2059 - 1s/epoch - 7ms/step
Epoch 16/100
210/210 - 1s - loss: 0.0320 - mse: 0.0639 - mae: 0.2004 - val_loss: 0.0371 - val_mse: 0.0742 - val_mae: 0.2090 - 1s/epoch - 7ms/step
Epoch 17/100
210/210 - 1s - loss: 0.0305 - mse: 0.0609 - mae: 0.1958 - val_loss: 0.0358 - val_mse: 0.0716 - val_mae: 0.2052 - 1s/epoch - 7ms/step
Epoch 18/100
210/210 - 1s - loss: 0.0291 - mse: 0.0582 - mae: 0.1907 - val_loss: 0.0290 - val_mse: 0.0580 - val_mae: 0.1896 - 1s/epoch - 7ms/step
Epoch 19/100
210/210 - 1s - loss: 0.0280 - mse: 0.0559 - mae: 0.1870 - val_loss: 0.0278 - val_mse: 0.0556 - val_mae: 0.1857 - 1s/epoch - 7ms/step
Epoch 20/100
210/210 - 1s - loss: 0.0269 - mse: 0.0537 - mae: 0.1828 - val_loss: 0.0271 - val_mse: 0.0542 - val_mae: 0.1833 - 1s/epoch - 7ms/step
Epoch 21/100
210/210 - 1s - loss: 0.0258 - mse: 0.0516 - mae: 0.1772 - val_loss: 0.0264 - val_mse: 0.0528 - val_mae: 0.1814 - 1s/epoch - 7ms/step
Epoch 22/100
210/210 - 1s - loss: 0.0249 - mse: 0.0498 - mae: 0.1737 - val_loss: 0.0252 - val_mse: 0.0505 - val_mae: 0.1760 - 1s/epoch - 7ms/step
Epoch 23/100
210/210 - 1s - loss: 0.0239 - mse: 0.0478 - mae: 0.1692 - val_loss: 0.0309 - val_mse: 0.0618 - val_mae: 0.1902 - 1s/epoch - 6ms/step
Epoch 24/100
210/210 - 1s - loss: 0.0232 - mse: 0.0464 - mae: 0.1667 - val_loss: 0.0241 - val_mse: 0.0483 - val_mae: 0.1720 - 1s/epoch - 7ms/step
Epoch 25/100
210/210 - 1s - loss: 0.0223 - mse: 0.0446 - mae: 0.1627 - val_loss: 0.0229 - val_mse: 0.0459 - val_mae: 0.1667 - 1s/epoch - 7ms/step
Epoch 26/100
210/210 - 1s - loss: 0.0218 - mse: 0.0436 - mae: 0.1602 - val_loss: 0.0233 - val_mse: 0.0466 - val_mae: 0.1697 - 1s/epoch - 7ms/step
Epoch 27/100
210/210 - 1s - loss: 0.0212 - mse: 0.0425 - mae: 0.1574 - val_loss: 0.0215 - val_mse: 0.0430 - val_mae: 0.1594 - 1s/epoch - 7ms/step
Epoch 28/100
210/210 - 1s - loss: 0.0207 - mse: 0.0415 - mae: 0.1554 - val_loss: 0.0229 - val_mse: 0.0458 - val_mae: 0.1628 - 1s/epoch - 7ms/step
Epoch 29/100
210/210 - 1s - loss: 0.0204 - mse: 0.0409 - mae: 0.1537 - val_loss: 0.0279 - val_mse: 0.0559 - val_mae: 0.1883 - 1s/epoch - 7ms/step
Epoch 30/100
210/210 - 1s - loss: 0.0199 - mse: 0.0398 - mae: 0.1513 - val_loss: 0.0302 - val_mse: 0.0605 - val_mae: 0.1975 - 1s/epoch - 7ms/step
Epoch 31/100
210/210 - 1s - loss: 0.0196 - mse: 0.0392 - mae: 0.1497 - val_loss: 0.0247 - val_mse: 0.0493 - val_mae: 0.1696 - 1s/epoch - 7ms/step
Epoch 32/100
210/210 - 1s - loss: 0.0192 - mse: 0.0384 - mae: 0.1474 - val_loss: 0.0196 - val_mse: 0.0391 - val_mae: 0.1501 - 1s/epoch - 7ms/step
Epoch 33/100
210/210 - 1s - loss: 0.0189 - mse: 0.0379 - mae: 0.1468 - val_loss: 0.0226 - val_mse: 0.0451 - val_mae: 0.1645 - 1s/epoch - 6ms/step
Epoch 34/100
210/210 - 1s - loss: 0.0187 - mse: 0.0373 - mae: 0.1454 - val_loss: 0.0215 - val_mse: 0.0429 - val_mae: 0.1586 - 1s/epoch - 6ms/step
Epoch 35/100
210/210 - 1s - loss: 0.0184 - mse: 0.0367 - mae: 0.1441 - val_loss: 0.0241 - val_mse: 0.0482 - val_mae: 0.1709 - 1s/epoch - 7ms/step
Epoch 36/100
210/210 - 1s - loss: 0.0182 - mse: 0.0363 - mae: 0.1430 - val_loss: 0.0186 - val_mse: 0.0373 - val_mae: 0.1448 - 1s/epoch - 7ms/step
Epoch 37/100
210/210 - 1s - loss: 0.0180 - mse: 0.0360 - mae: 0.1422 - val_loss: 0.0232 - val_mse: 0.0464 - val_mae: 0.1645 - 1s/epoch - 6ms/step
Epoch 38/100
210/210 - 1s - loss: 0.0177 - mse: 0.0353 - mae: 0.1406 - val_loss: 0.0204 - val_mse: 0.0409 - val_mae: 0.1533 - 1s/epoch - 7ms/step
Epoch 39/100
210/210 - 1s - loss: 0.0175 - mse: 0.0350 - mae: 0.1399 - val_loss: 0.0182 - val_mse: 0.0363 - val_mae: 0.1425 - 1s/epoch - 6ms/step
Epoch 40/100
210/210 - 1s - loss: 0.0174 - mse: 0.0347 - mae: 0.1389 - val_loss: 0.0216 - val_mse: 0.0431 - val_mae: 0.1566 - 1s/epoch - 6ms/step
Epoch 41/100
210/210 - 1s - loss: 0.0172 - mse: 0.0343 - mae: 0.1381 - val_loss: 0.0176 - val_mse: 0.0352 - val_mae: 0.1397 - 1s/epoch - 7ms/step
Epoch 42/100
210/210 - 1s - loss: 0.0169 - mse: 0.0339 - mae: 0.1370 - val_loss: 0.0207 - val_mse: 0.0414 - val_mae: 0.1542 - 1s/epoch - 7ms/step
Epoch 43/100
210/210 - 1s - loss: 0.0169 - mse: 0.0338 - mae: 0.1369 - val_loss: 0.0275 - val_mse: 0.0551 - val_mae: 0.1814 - 1s/epoch - 7ms/step
Epoch 44/100
210/210 - 1s - loss: 0.0168 - mse: 0.0336 - mae: 0.1362 - val_loss: 0.0171 - val_mse: 0.0342 - val_mae: 0.1378 - 1s/epoch - 7ms/step
Epoch 45/100
210/210 - 1s - loss: 0.0166 - mse: 0.0332 - mae: 0.1357 - val_loss: 0.0184 - val_mse: 0.0368 - val_mae: 0.1440 - 1s/epoch - 7ms/step
Epoch 46/100
210/210 - 1s - loss: 0.0164 - mse: 0.0328 - mae: 0.1343 - val_loss: 0.0175 - val_mse: 0.0351 - val_mae: 0.1402 - 1s/epoch - 7ms/step
Epoch 47/100
210/210 - 1s - loss: 0.0165 - mse: 0.0329 - mae: 0.1343 - val_loss: 0.0169 - val_mse: 0.0338 - val_mae: 0.1369 - 1s/epoch - 7ms/step
Epoch 48/100
210/210 - 1s - loss: 0.0165 - mse: 0.0330 - mae: 0.1349 - val_loss: 0.0179 - val_mse: 0.0357 - val_mae: 0.1410 - 1s/epoch - 6ms/step
Epoch 49/100
210/210 - 1s - loss: 0.0163 - mse: 0.0325 - mae: 0.1341 - val_loss: 0.0210 - val_mse: 0.0421 - val_mae: 0.1545 - 1s/epoch - 7ms/step
Epoch 50/100
210/210 - 1s - loss: 0.0161 - mse: 0.0322 - mae: 0.1335 - val_loss: 0.0168 - val_mse: 0.0336 - val_mae: 0.1363 - 1s/epoch - 6ms/step
Epoch 51/100
210/210 - 1s - loss: 0.0160 - mse: 0.0320 - mae: 0.1328 - val_loss: 0.0177 - val_mse: 0.0353 - val_mae: 0.1401 - 1s/epoch - 7ms/step
Epoch 52/100
210/210 - 1s - loss: 0.0160 - mse: 0.0320 - mae: 0.1325 - val_loss: 0.0215 - val_mse: 0.0430 - val_mae: 0.1577 - 1s/epoch - 6ms/step
Epoch 53/100
210/210 - 1s - loss: 0.0160 - mse: 0.0319 - mae: 0.1321 - val_loss: 0.0167 - val_mse: 0.0334 - val_mae: 0.1355 - 1s/epoch - 7ms/step
Epoch 54/100
210/210 - 1s - loss: 0.0159 - mse: 0.0318 - mae: 0.1319 - val_loss: 0.0240 - val_mse: 0.0479 - val_mae: 0.1680 - 1s/epoch - 7ms/step
Epoch 55/100
210/210 - 1s - loss: 0.0158 - mse: 0.0315 - mae: 0.1315 - val_loss: 0.0196 - val_mse: 0.0393 - val_mae: 0.1493 - 1s/epoch - 7ms/step
Epoch 56/100
210/210 - 1s - loss: 0.0157 - mse: 0.0313 - mae: 0.1311 - val_loss: 0.0175 - val_mse: 0.0351 - val_mae: 0.1397 - 1s/epoch - 7ms/step
Epoch 57/100
210/210 - 1s - loss: 0.0156 - mse: 0.0311 - mae: 0.1307 - val_loss: 0.0223 - val_mse: 0.0446 - val_mae: 0.1588 - 1s/epoch - 7ms/step
Epoch 58/100
210/210 - 1s - loss: 0.0155 - mse: 0.0311 - mae: 0.1306 - val_loss: 0.0189 - val_mse: 0.0378 - val_mae: 0.1452 - 1s/epoch - 7ms/step
Epoch 59/100
210/210 - 1s - loss: 0.0153 - mse: 0.0306 - mae: 0.1298 - val_loss: 0.0167 - val_mse: 0.0334 - val_mae: 0.1353 - 1s/epoch - 7ms/step
Epoch 60/100
210/210 - 1s - loss: 0.0154 - mse: 0.0307 - mae: 0.1303 - val_loss: 0.0162 - val_mse: 0.0324 - val_mae: 0.1337 - 1s/epoch - 7ms/step
Epoch 61/100
210/210 - 1s - loss: 0.0154 - mse: 0.0307 - mae: 0.1299 - val_loss: 0.0168 - val_mse: 0.0337 - val_mae: 0.1357 - 1s/epoch - 6ms/step
Epoch 62/100
210/210 - 1s - loss: 0.0152 - mse: 0.0304 - mae: 0.1297 - val_loss: 0.0171 - val_mse: 0.0342 - val_mae: 0.1375 - 1s/epoch - 6ms/step
Epoch 63/100
210/210 - 1s - loss: 0.0152 - mse: 0.0303 - mae: 0.1297 - val_loss: 0.0173 - val_mse: 0.0346 - val_mae: 0.1382 - 1s/epoch - 7ms/step
Epoch 64/100
210/210 - 1s - loss: 0.0153 - mse: 0.0306 - mae: 0.1297 - val_loss: 0.0206 - val_mse: 0.0411 - val_mae: 0.1529 - 1s/epoch - 7ms/step
Epoch 65/100
210/210 - 1s - loss: 0.0151 - mse: 0.0302 - mae: 0.1290 - val_loss: 0.0179 - val_mse: 0.0359 - val_mae: 0.1415 - 1s/epoch - 7ms/step
Epoch 66/100
210/210 - 1s - loss: 0.0151 - mse: 0.0301 - mae: 0.1284 - val_loss: 0.0176 - val_mse: 0.0352 - val_mae: 0.1385 - 1s/epoch - 6ms/step
Epoch 67/100
210/210 - 1s - loss: 0.0148 - mse: 0.0296 - mae: 0.1274 - val_loss: 0.0160 - val_mse: 0.0321 - val_mae: 0.1328 - 1s/epoch - 6ms/step
Epoch 68/100
210/210 - 1s - loss: 0.0151 - mse: 0.0302 - mae: 0.1285 - val_loss: 0.0198 - val_mse: 0.0397 - val_mae: 0.1492 - 1s/epoch - 7ms/step
Epoch 69/100
210/210 - 1s - loss: 0.0150 - mse: 0.0300 - mae: 0.1282 - val_loss: 0.0161 - val_mse: 0.0321 - val_mae: 0.1332 - 1s/epoch - 6ms/step
Epoch 70/100
210/210 - 1s - loss: 0.0149 - mse: 0.0298 - mae: 0.1278 - val_loss: 0.0187 - val_mse: 0.0374 - val_mae: 0.1445 - 1s/epoch - 7ms/step
Epoch 71/100
210/210 - 1s - loss: 0.0148 - mse: 0.0296 - mae: 0.1278 - val_loss: 0.0210 - val_mse: 0.0419 - val_mae: 0.1540 - 1s/epoch - 7ms/step
Epoch 72/100
210/210 - 1s - loss: 0.0147 - mse: 0.0294 - mae: 0.1270 - val_loss: 0.0163 - val_mse: 0.0325 - val_mae: 0.1353 - 1s/epoch - 7ms/step
Epoch 73/100
210/210 - 1s - loss: 0.0148 - mse: 0.0296 - mae: 0.1278 - val_loss: 0.0157 - val_mse: 0.0313 - val_mae: 0.1318 - 1s/epoch - 7ms/step
Epoch 74/100
210/210 - 1s - loss: 0.0146 - mse: 0.0293 - mae: 0.1269 - val_loss: 0.0205 - val_mse: 0.0410 - val_mae: 0.1527 - 1s/epoch - 7ms/step
Epoch 75/100
210/210 - 1s - loss: 0.0146 - mse: 0.0291 - mae: 0.1270 - val_loss: 0.0186 - val_mse: 0.0373 - val_mae: 0.1439 - 1s/epoch - 7ms/step
Epoch 76/100
210/210 - 1s - loss: 0.0145 - mse: 0.0289 - mae: 0.1263 - val_loss: 0.0234 - val_mse: 0.0468 - val_mae: 0.1598 - 1s/epoch - 7ms/step
Epoch 77/100
210/210 - 1s - loss: 0.0146 - mse: 0.0292 - mae: 0.1265 - val_loss: 0.0224 - val_mse: 0.0449 - val_mae: 0.1589 - 1s/epoch - 7ms/step
Epoch 78/100
210/210 - 1s - loss: 0.0146 - mse: 0.0291 - mae: 0.1265 - val_loss: 0.0162 - val_mse: 0.0325 - val_mae: 0.1341 - 1s/epoch - 6ms/step
Epoch 79/100
210/210 - 1s - loss: 0.0145 - mse: 0.0289 - mae: 0.1259 - val_loss: 0.0176 - val_mse: 0.0352 - val_mae: 0.1388 - 1s/epoch - 7ms/step
Epoch 80/100
210/210 - 1s - loss: 0.0146 - mse: 0.0292 - mae: 0.1257 - val_loss: 0.0195 - val_mse: 0.0390 - val_mae: 0.1496 - 1s/epoch - 6ms/step
Epoch 81/100
210/210 - 1s - loss: 0.0145 - mse: 0.0289 - mae: 0.1261 - val_loss: 0.0172 - val_mse: 0.0343 - val_mae: 0.1375 - 1s/epoch - 6ms/step
Epoch 82/100
210/210 - 1s - loss: 0.0145 - mse: 0.0289 - mae: 0.1261 - val_loss: 0.0192 - val_mse: 0.0385 - val_mae: 0.1427 - 1s/epoch - 7ms/step
Epoch 83/100
Restoring model weights from the end of the best epoch: 73.
210/210 - 1s - loss: 0.0145 - mse: 0.0289 - mae: 0.1267 - val_loss: 0.0210 - val_mse: 0.0419 - val_mae: 0.1560 - 1s/epoch - 7ms/step
Epoch 83: early stopping
(2974, 80, 15)
 1/93 [..............................] - ETA: 28s25/93 [=======>......................] - ETA: 0s 50/93 [===============>..............] - ETA: 0s75/93 [=======================>......] - ETA: 0s93/93 [==============================] - ETA: 0s93/93 [==============================] - 1s 3ms/step
R^2: 0.6825185430751464
Mean Absolute Error (MAE): 0.13064385266870285
Mean Squared Error (MSE): 0.0316295512374336
Mean Absolute Percentage Error (MAPE): 8.62947176721959
Root Mean Squared Error (RMSE): 0.17784698827203568
Explained Variance Score: 0.6829552623905886
Max Error: 0.8682295579308741
Mean Squared Log Error: 0.014667555655418753
Median Absolute Error: 0.09804114480894383
