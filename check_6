2023-12-14 18:03:18.791733: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-12-14 18:03:30.281191: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31141 MB memory:  -> device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:3b:00.0, compute capability: 7.0
2023-12-14 18:03:30.296326: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31141 MB memory:  -> device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:3b:00.0, compute capability: 7.0
SCRIPT INITIATED
INI
MODE 3
['S1_CrestFactor_g~g', 'S1_DerivedPeak_g', 'S1_Peak~Peak_g', 'S1_RMS_g', 'S1_TruePeak_g', 'S1_HighFrequency_grms', 'S1_Kurtosis_g~g', 'S2_CrestFactor_g~g', 'S2_DerivedPeak_g', 'S2_Peak~Peak_g', 'S2_RMS_g', 'S2_TruePeak_g', 'S2_HighFrequency_grms', 'S2_Kurtosis_g~g']
0         2009308.0
1         2009307.0
2         2009306.0
3         2009305.0
4         2009304.0
            ...    
238239        499.0
238240        498.0
238241        497.0
238242        496.0
238243        495.0
Name: rul, Length: 238244, dtype: float64
range(0, 238244)
Index(['S1_CrestFactor_g~g', 'S1_DerivedPeak_g', 'S1_Peak~Peak_g', 'S1_RMS_g',
       'S1_TruePeak_g', 'S1_HighFrequency_grms', 'S1_Kurtosis_g~g',
       'S2_CrestFactor_g~g', 'S2_DerivedPeak_g', 'S2_Peak~Peak_g', 'S2_RMS_g',
       'S2_TruePeak_g', 'S2_HighFrequency_grms', 'S2_Kurtosis_g~g', 'S1_temp',
       'status'],
      dtype='object')
rul
TRAIN_INPUT CHECK
[[[ 2.3585  0.7762  2.5544 ...  3.0062 72.4641  1.    ]
  [ 2.4198  0.7771  2.5854 ...  2.9001 72.5021  1.    ]
  [ 2.3189  0.7775  2.5159 ...  2.9509 72.5413  1.    ]
  ...
  [ 2.4077  0.779   2.5626 ...  3.0882 72.7793  1.    ]
  [ 2.354   0.781   2.5615 ...  3.2563 72.7835  1.    ]
  [ 2.3529  0.777   2.5633 ...  2.989  72.7993  1.    ]]

 [[ 2.4175  0.7667  2.5422 ...  2.9308 72.3851  1.    ]
  [ 2.3634  0.763   2.5201 ...  2.9289 72.4113  1.    ]
  [ 2.3603  0.7637  2.5439 ...  3.0104 72.3761  1.    ]
  ...
  [ 2.3679  0.7642  2.5345 ...  3.0965 72.3141  1.    ]
  [ 2.3275  0.7629  2.5105 ...  2.9623 72.2949  1.    ]
  [ 2.4366  0.7647  2.5581 ...  2.9887 72.2924  1.    ]]

 [[ 2.4125  0.6274  2.062  ...  2.8344 73.8363  0.    ]
  [ 2.3855  0.6304  2.0422 ...  2.8124 73.849   0.    ]
  [ 2.3764  0.6309  2.048  ...  2.7976 73.8439  0.    ]
  ...
  [ 2.3602  0.6299  2.0171 ...  2.7916 73.8569  0.    ]
  [ 2.3869  0.6339  2.1204 ...  2.8103 73.8002  0.    ]
  [ 2.3153  0.6336  2.0457 ...  2.8023 73.8282  0.    ]]

 ...

 [[ 2.5085  0.7042  2.4657 ...  2.9406 72.954   2.    ]
  [ 2.4459  0.7025  2.3853 ...  3.0427 72.9865  2.    ]
  [ 2.5687  0.7043  2.5122 ...  2.9178 72.9309  2.    ]
  ...
  [ 2.504   0.71    2.4491 ...  3.0354 73.2192  2.    ]
  [ 2.459   0.7087  2.4643 ...  2.9183 73.187   2.    ]
  [ 2.4688  0.7087  2.4442 ...  2.8741 73.2175  2.    ]]

 [[ 2.3908  0.7735  2.5659 ...  3.089  72.5209  1.    ]
  [ 2.3726  0.773   2.4997 ...  3.2154 72.5112  1.    ]
  [ 2.4679  0.7686  2.5831 ...  2.9967 72.535   1.    ]
  ...
  [ 2.3619  0.7794  2.5439 ...  3.0569 72.8032  1.    ]
  [ 2.325   0.7801  2.5233 ...  2.9633 72.7882  1.    ]
  [ 2.3586  0.7768  2.5182 ...  3.2712 72.8072  1.    ]]

 [[ 2.5245  0.7154  2.4835 ...  2.8527 72.7917  2.    ]
  [ 2.5612  0.7177  2.5409 ...  2.9955 72.7948  2.    ]
  [ 2.4428  0.7176  2.4709 ...  2.8543 72.7769  2.    ]
  ...
  [ 2.4827  0.7169  2.4823 ...  2.8761 72.9115  2.    ]
  [ 2.5775  0.7151  2.5433 ...  2.9191 72.8317  2.    ]
  [ 2.5099  0.7168  2.5121 ...  2.8226 72.898   2.    ]]]
(6691, 80, 16)
(6691, 80, 15)
train_out
(6691, 1)
test_out
(2974, 1)
vals_out
[[  17175.]
 [1317475.]
 [1388053.]
 ...
 [1475663.]
 [ 169730.]
 [1212322.]]
(2231, 1)
[[0.00826424]
 [0.65561349]
 [0.69075047]
 ...
 [0.73436676]
 [0.08421315]
 [0.60326348]]
(2231, 1)
(6691, 80, 15)
(2974, 80, 15)
(2231, 80, 15)
logs/fit/20231214-180330
Epoch 1/100
2023-12-14 18:03:32.796090: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600
2023-12-14 18:03:33.060618: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbc5b66a7f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-12-14 18:03:33.060666: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0
2023-12-14 18:03:33.066380: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-12-14 18:03:33.171745: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
210/210 - 6s - loss: 2.8545 - mse: 33.0232 - mae: 3.2742 - val_loss: 0.2330 - val_mse: 0.4794 - val_mae: 0.5927 - 6s/epoch - 29ms/step
Epoch 2/100
210/210 - 1s - loss: 0.2092 - mse: 0.4300 - mae: 0.5570 - val_loss: 0.1824 - val_mse: 0.3695 - val_mae: 0.5102 - 1s/epoch - 7ms/step
Epoch 3/100
210/210 - 1s - loss: 0.1386 - mse: 0.2819 - mae: 0.4385 - val_loss: 0.0924 - val_mse: 0.1856 - val_mae: 0.3547 - 1s/epoch - 6ms/step
Epoch 4/100
210/210 - 1s - loss: 0.0677 - mse: 0.1357 - mae: 0.2998 - val_loss: 0.0569 - val_mse: 0.1138 - val_mae: 0.2688 - 1s/epoch - 6ms/step
Epoch 5/100
210/210 - 1s - loss: 0.0521 - mse: 0.1042 - mae: 0.2521 - val_loss: 0.0517 - val_mse: 0.1033 - val_mae: 0.2522 - 1s/epoch - 6ms/step
Epoch 6/100
210/210 - 1s - loss: 0.0493 - mse: 0.0987 - mae: 0.2423 - val_loss: 0.0508 - val_mse: 0.1016 - val_mae: 0.2472 - 1s/epoch - 7ms/step
Epoch 7/100
210/210 - 1s - loss: 0.0484 - mse: 0.0968 - mae: 0.2398 - val_loss: 0.0511 - val_mse: 0.1021 - val_mae: 0.2425 - 1s/epoch - 7ms/step
Epoch 8/100
210/210 - 1s - loss: 0.0477 - mse: 0.0954 - mae: 0.2377 - val_loss: 0.0504 - val_mse: 0.1009 - val_mae: 0.2483 - 1s/epoch - 7ms/step
Epoch 9/100
210/210 - 1s - loss: 0.0470 - mse: 0.0940 - mae: 0.2366 - val_loss: 0.0500 - val_mse: 0.1000 - val_mae: 0.2448 - 1s/epoch - 7ms/step
Epoch 10/100
210/210 - 1s - loss: 0.0463 - mse: 0.0927 - mae: 0.2360 - val_loss: 0.0495 - val_mse: 0.0989 - val_mae: 0.2513 - 1s/epoch - 7ms/step
Epoch 11/100
210/210 - 1s - loss: 0.0459 - mse: 0.0918 - mae: 0.2361 - val_loss: 0.0491 - val_mse: 0.0983 - val_mae: 0.2438 - 1s/epoch - 7ms/step
Epoch 12/100
210/210 - 1s - loss: 0.0456 - mse: 0.0912 - mae: 0.2350 - val_loss: 0.0486 - val_mse: 0.0973 - val_mae: 0.2480 - 1s/epoch - 7ms/step
Epoch 13/100
210/210 - 1s - loss: 0.0452 - mse: 0.0904 - mae: 0.2349 - val_loss: 0.0485 - val_mse: 0.0970 - val_mae: 0.2430 - 1s/epoch - 7ms/step
Epoch 14/100
210/210 - 1s - loss: 0.0446 - mse: 0.0893 - mae: 0.2340 - val_loss: 0.0478 - val_mse: 0.0956 - val_mae: 0.2490 - 1s/epoch - 6ms/step
Epoch 15/100
210/210 - 1s - loss: 0.0440 - mse: 0.0879 - mae: 0.2338 - val_loss: 0.0464 - val_mse: 0.0929 - val_mae: 0.2416 - 1s/epoch - 7ms/step
Epoch 16/100
210/210 - 1s - loss: 0.0427 - mse: 0.0855 - mae: 0.2311 - val_loss: 0.0450 - val_mse: 0.0900 - val_mae: 0.2372 - 1s/epoch - 7ms/step
Epoch 17/100
210/210 - 1s - loss: 0.0413 - mse: 0.0826 - mae: 0.2283 - val_loss: 0.0429 - val_mse: 0.0858 - val_mae: 0.2354 - 1s/epoch - 6ms/step
Epoch 18/100
210/210 - 1s - loss: 0.0396 - mse: 0.0793 - mae: 0.2247 - val_loss: 0.0414 - val_mse: 0.0827 - val_mae: 0.2332 - 1s/epoch - 6ms/step
Epoch 19/100
210/210 - 1s - loss: 0.0378 - mse: 0.0757 - mae: 0.2196 - val_loss: 0.0392 - val_mse: 0.0784 - val_mae: 0.2294 - 1s/epoch - 7ms/step
Epoch 20/100
210/210 - 1s - loss: 0.0355 - mse: 0.0709 - mae: 0.2125 - val_loss: 0.0352 - val_mse: 0.0705 - val_mae: 0.2144 - 1s/epoch - 7ms/step
Epoch 21/100
210/210 - 1s - loss: 0.0324 - mse: 0.0649 - mae: 0.2030 - val_loss: 0.0329 - val_mse: 0.0658 - val_mae: 0.2028 - 1s/epoch - 6ms/step
Epoch 22/100
210/210 - 1s - loss: 0.0297 - mse: 0.0594 - mae: 0.1938 - val_loss: 0.0305 - val_mse: 0.0610 - val_mae: 0.1947 - 1s/epoch - 6ms/step
Epoch 23/100
210/210 - 1s - loss: 0.0280 - mse: 0.0560 - mae: 0.1874 - val_loss: 0.0288 - val_mse: 0.0575 - val_mae: 0.1879 - 1s/epoch - 6ms/step
Epoch 24/100
210/210 - 1s - loss: 0.0262 - mse: 0.0525 - mae: 0.1798 - val_loss: 0.0285 - val_mse: 0.0570 - val_mae: 0.1891 - 1s/epoch - 7ms/step
Epoch 25/100
210/210 - 1s - loss: 0.0250 - mse: 0.0500 - mae: 0.1739 - val_loss: 0.0266 - val_mse: 0.0532 - val_mae: 0.1798 - 1s/epoch - 7ms/step
Epoch 26/100
210/210 - 1s - loss: 0.0238 - mse: 0.0476 - mae: 0.1686 - val_loss: 0.0260 - val_mse: 0.0521 - val_mae: 0.1725 - 1s/epoch - 7ms/step
Epoch 27/100
210/210 - 1s - loss: 0.0229 - mse: 0.0458 - mae: 0.1644 - val_loss: 0.0307 - val_mse: 0.0615 - val_mae: 0.1863 - 1s/epoch - 7ms/step
Epoch 28/100
210/210 - 1s - loss: 0.0223 - mse: 0.0446 - mae: 0.1610 - val_loss: 0.0289 - val_mse: 0.0578 - val_mae: 0.1796 - 1s/epoch - 6ms/step
Epoch 29/100
210/210 - 1s - loss: 0.0218 - mse: 0.0436 - mae: 0.1592 - val_loss: 0.0295 - val_mse: 0.0591 - val_mae: 0.1825 - 1s/epoch - 6ms/step
Epoch 30/100
210/210 - 1s - loss: 0.0212 - mse: 0.0424 - mae: 0.1562 - val_loss: 0.0247 - val_mse: 0.0494 - val_mae: 0.1699 - 1s/epoch - 6ms/step
Epoch 31/100
210/210 - 1s - loss: 0.0209 - mse: 0.0418 - mae: 0.1548 - val_loss: 0.0231 - val_mse: 0.0462 - val_mae: 0.1593 - 1s/epoch - 7ms/step
Epoch 32/100
210/210 - 1s - loss: 0.0203 - mse: 0.0407 - mae: 0.1518 - val_loss: 0.0260 - val_mse: 0.0520 - val_mae: 0.1743 - 1s/epoch - 7ms/step
Epoch 33/100
210/210 - 1s - loss: 0.0200 - mse: 0.0400 - mae: 0.1509 - val_loss: 0.0241 - val_mse: 0.0482 - val_mae: 0.1613 - 1s/epoch - 7ms/step
Epoch 34/100
210/210 - 1s - loss: 0.0198 - mse: 0.0395 - mae: 0.1491 - val_loss: 0.0221 - val_mse: 0.0443 - val_mae: 0.1544 - 1s/epoch - 7ms/step
Epoch 35/100
210/210 - 1s - loss: 0.0194 - mse: 0.0388 - mae: 0.1475 - val_loss: 0.0223 - val_mse: 0.0446 - val_mae: 0.1547 - 1s/epoch - 6ms/step
Epoch 36/100
210/210 - 1s - loss: 0.0192 - mse: 0.0383 - mae: 0.1460 - val_loss: 0.0220 - val_mse: 0.0439 - val_mae: 0.1548 - 1s/epoch - 6ms/step
Epoch 37/100
210/210 - 1s - loss: 0.0190 - mse: 0.0381 - mae: 0.1456 - val_loss: 0.0236 - val_mse: 0.0471 - val_mae: 0.1631 - 1s/epoch - 6ms/step
Epoch 38/100
210/210 - 1s - loss: 0.0189 - mse: 0.0377 - mae: 0.1440 - val_loss: 0.0221 - val_mse: 0.0443 - val_mae: 0.1536 - 1s/epoch - 6ms/step
Epoch 39/100
210/210 - 1s - loss: 0.0187 - mse: 0.0374 - mae: 0.1436 - val_loss: 0.0217 - val_mse: 0.0433 - val_mae: 0.1526 - 1s/epoch - 6ms/step
Epoch 40/100
210/210 - 1s - loss: 0.0185 - mse: 0.0370 - mae: 0.1423 - val_loss: 0.0223 - val_mse: 0.0446 - val_mae: 0.1527 - 1s/epoch - 6ms/step
Epoch 41/100
210/210 - 1s - loss: 0.0184 - mse: 0.0368 - mae: 0.1422 - val_loss: 0.0240 - val_mse: 0.0480 - val_mae: 0.1603 - 1s/epoch - 6ms/step
Epoch 42/100
210/210 - 1s - loss: 0.0184 - mse: 0.0368 - mae: 0.1418 - val_loss: 0.0212 - val_mse: 0.0425 - val_mae: 0.1506 - 1s/epoch - 6ms/step
Epoch 43/100
210/210 - 1s - loss: 0.0183 - mse: 0.0366 - mae: 0.1412 - val_loss: 0.0219 - val_mse: 0.0438 - val_mae: 0.1514 - 1s/epoch - 6ms/step
Epoch 44/100
210/210 - 1s - loss: 0.0180 - mse: 0.0360 - mae: 0.1399 - val_loss: 0.0217 - val_mse: 0.0435 - val_mae: 0.1510 - 1s/epoch - 6ms/step
Epoch 45/100
210/210 - 1s - loss: 0.0179 - mse: 0.0358 - mae: 0.1390 - val_loss: 0.0211 - val_mse: 0.0422 - val_mae: 0.1483 - 1s/epoch - 6ms/step
Epoch 46/100
210/210 - 1s - loss: 0.0177 - mse: 0.0355 - mae: 0.1384 - val_loss: 0.0209 - val_mse: 0.0417 - val_mae: 0.1484 - 1s/epoch - 6ms/step
Epoch 47/100
210/210 - 1s - loss: 0.0176 - mse: 0.0353 - mae: 0.1386 - val_loss: 0.0234 - val_mse: 0.0468 - val_mae: 0.1569 - 1s/epoch - 6ms/step
Epoch 48/100
210/210 - 1s - loss: 0.0175 - mse: 0.0351 - mae: 0.1377 - val_loss: 0.0209 - val_mse: 0.0418 - val_mae: 0.1469 - 1s/epoch - 6ms/step
Epoch 49/100
210/210 - 1s - loss: 0.0174 - mse: 0.0349 - mae: 0.1374 - val_loss: 0.0232 - val_mse: 0.0465 - val_mae: 0.1594 - 1s/epoch - 6ms/step
Epoch 50/100
210/210 - 1s - loss: 0.0174 - mse: 0.0348 - mae: 0.1367 - val_loss: 0.0210 - val_mse: 0.0420 - val_mae: 0.1472 - 1s/epoch - 6ms/step
Epoch 51/100
210/210 - 1s - loss: 0.0173 - mse: 0.0346 - mae: 0.1362 - val_loss: 0.0219 - val_mse: 0.0438 - val_mae: 0.1526 - 1s/epoch - 6ms/step
Epoch 52/100
210/210 - 1s - loss: 0.0172 - mse: 0.0343 - mae: 0.1356 - val_loss: 0.0221 - val_mse: 0.0441 - val_mae: 0.1533 - 1s/epoch - 6ms/step
Epoch 53/100
210/210 - 1s - loss: 0.0172 - mse: 0.0344 - mae: 0.1361 - val_loss: 0.0220 - val_mse: 0.0441 - val_mae: 0.1533 - 1s/epoch - 7ms/step
Epoch 54/100
210/210 - 1s - loss: 0.0170 - mse: 0.0340 - mae: 0.1350 - val_loss: 0.0207 - val_mse: 0.0413 - val_mae: 0.1454 - 1s/epoch - 7ms/step
Epoch 55/100
210/210 - 1s - loss: 0.0170 - mse: 0.0341 - mae: 0.1355 - val_loss: 0.0207 - val_mse: 0.0413 - val_mae: 0.1458 - 1s/epoch - 6ms/step
Epoch 56/100
210/210 - 1s - loss: 0.0170 - mse: 0.0340 - mae: 0.1346 - val_loss: 0.0208 - val_mse: 0.0416 - val_mae: 0.1463 - 1s/epoch - 6ms/step
Epoch 57/100
210/210 - 1s - loss: 0.0169 - mse: 0.0337 - mae: 0.1340 - val_loss: 0.0220 - val_mse: 0.0441 - val_mae: 0.1535 - 1s/epoch - 6ms/step
Epoch 58/100
210/210 - 1s - loss: 0.0167 - mse: 0.0335 - mae: 0.1333 - val_loss: 0.0213 - val_mse: 0.0426 - val_mae: 0.1478 - 1s/epoch - 6ms/step
Epoch 59/100
210/210 - 1s - loss: 0.0168 - mse: 0.0336 - mae: 0.1338 - val_loss: 0.0222 - val_mse: 0.0444 - val_mae: 0.1548 - 1s/epoch - 6ms/step
Epoch 60/100
210/210 - 1s - loss: 0.0167 - mse: 0.0335 - mae: 0.1332 - val_loss: 0.0216 - val_mse: 0.0432 - val_mae: 0.1515 - 1s/epoch - 6ms/step
Epoch 61/100
210/210 - 1s - loss: 0.0167 - mse: 0.0333 - mae: 0.1328 - val_loss: 0.0244 - val_mse: 0.0488 - val_mae: 0.1595 - 1s/epoch - 6ms/step
Epoch 62/100
210/210 - 1s - loss: 0.0165 - mse: 0.0331 - mae: 0.1325 - val_loss: 0.0208 - val_mse: 0.0416 - val_mae: 0.1457 - 1s/epoch - 6ms/step
Epoch 63/100
210/210 - 1s - loss: 0.0167 - mse: 0.0333 - mae: 0.1325 - val_loss: 0.0220 - val_mse: 0.0439 - val_mae: 0.1511 - 1s/epoch - 6ms/step
Epoch 64/100
Restoring model weights from the end of the best epoch: 54.
210/210 - 1s - loss: 0.0164 - mse: 0.0328 - mae: 0.1322 - val_loss: 0.0213 - val_mse: 0.0425 - val_mae: 0.1478 - 1s/epoch - 6ms/step
Epoch 64: early stopping
(2974, 80, 15)
 1/93 [..............................] - ETA: 27s28/93 [========>.....................] - ETA: 0s 56/93 [=================>............] - ETA: 0s84/93 [==========================>...] - ETA: 0s93/93 [==============================] - ETA: 0s93/93 [==============================] - 1s 3ms/step
R^2: 0.5912108802330582
Mean Absolute Error (MAE): 0.1440292512021035
Mean Squared Error (MSE): 0.04046496781401816
Mean Absolute Percentage Error (MAPE): 11198193715.154476
Root Mean Squared Error (RMSE): 0.20115906097916186
Explained Variance Score: 0.5950560399132387
Max Error: 0.9107130070408844
Mean Squared Log Error: 0.019064027144714207
Median Absolute Error: 0.10492475158096176
