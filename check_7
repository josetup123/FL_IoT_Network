2023-12-14 18:05:04.153960: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-12-14 18:05:16.241934: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31141 MB memory:  -> device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:3b:00.0, compute capability: 7.0
2023-12-14 18:05:16.266127: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31141 MB memory:  -> device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:3b:00.0, compute capability: 7.0
SCRIPT INITIATED
INI
MODE 3
['S1_CrestFactor_g~g', 'S1_DerivedPeak_g', 'S1_Peak~Peak_g', 'S1_RMS_g', 'S1_TruePeak_g', 'S1_HighFrequency_grms', 'S1_Kurtosis_g~g', 'S2_CrestFactor_g~g', 'S2_DerivedPeak_g', 'S2_Peak~Peak_g', 'S2_RMS_g', 'S2_TruePeak_g', 'S2_HighFrequency_grms', 'S2_Kurtosis_g~g']
0         2009308.0
1         2009307.0
2         2009306.0
3         2009305.0
4         2009304.0
            ...    
238239        499.0
238240        498.0
238241        497.0
238242        496.0
238243        495.0
Name: rul, Length: 238244, dtype: float64
range(0, 238244)
Index(['S1_CrestFactor_g~g', 'S1_DerivedPeak_g', 'S1_Peak~Peak_g', 'S1_RMS_g',
       'S1_TruePeak_g', 'S1_HighFrequency_grms', 'S1_Kurtosis_g~g',
       'S2_CrestFactor_g~g', 'S2_DerivedPeak_g', 'S2_Peak~Peak_g', 'S2_RMS_g',
       'S2_TruePeak_g', 'S2_HighFrequency_grms', 'S2_Kurtosis_g~g', 'S1_temp',
       'status'],
      dtype='object')
rul
TRAIN_INPUT CHECK
[[[ 2.4005  0.7767  2.5665 ...  2.7902 72.5741  1.    ]
  [ 2.4274  0.7766  2.6008 ...  2.955  72.6485  1.    ]
  [ 2.464   0.7749  2.6558 ...  2.9033 72.6498  1.    ]
  ...
  [ 2.3754  0.7767  2.5933 ...  2.9537 72.5094  1.    ]
  [ 2.2655  0.7775  2.4797 ...  3.3116 72.5405  1.    ]
  [ 2.4563  0.7804  2.6357 ...  3.1263 72.4936  1.    ]]

 [[ 2.3158  0.6319  2.0277 ...  2.878  73.0839  0.    ]
  [ 2.3606  0.6315  2.0779 ...  3.0572 73.0805  0.    ]
  [ 2.4683  0.6329  2.1161 ...  2.8953 73.0348  0.    ]
  ...
  [ 2.3633  0.6297  2.0078 ...  2.7326 72.9968  0.    ]
  [ 2.42    0.6269  2.1214 ...  2.7144 73.0745  0.    ]
  [ 2.372   0.6276  2.0747 ...  2.7933 73.0395  0.    ]]

 [[ 2.4967  0.7716  2.6102 ...  3.123  72.7088  1.    ]
  [ 2.3736  0.7698  2.5105 ...  2.9323 72.8456  1.    ]
  [ 2.4656  0.7665  2.5546 ...  2.9178 72.8017  1.    ]
  ...
  [ 2.465   0.7679  2.5952 ...  2.8773 72.6231  1.    ]
  [ 2.4009  0.7685  2.5883 ...  2.9597 72.6231  1.    ]
  [ 2.4282  0.7676  2.5906 ...  2.9253 72.6236  1.    ]]

 ...

 [[ 2.6469  0.7153  2.5598 ...  2.9185 72.753   2.    ]
  [ 2.5241  0.7132  2.4993 ...  2.9978 72.7582  2.    ]
  [ 2.5224  0.713   2.5164 ...  2.9457 72.7817  2.    ]
  ...
  [ 2.4609  0.7097  2.4542 ...  2.8811 72.5021  2.    ]
  [ 2.5307  0.7122  2.5247 ...  2.9313 72.4841  2.    ]
  [ 2.4424  0.7113  2.4515 ...  3.1745 72.5708  2.    ]]

 [[ 2.4387  0.7571  2.5742 ...  2.7948 73.4513  1.    ]
  [ 2.4363  0.7568  2.5291 ...  2.9298 73.4682  1.    ]
  [ 2.3848  0.7588  2.5243 ...  2.9141 73.4751  1.    ]
  ...
  [ 2.5291  0.7597  2.5903 ...  2.9514 73.5544  1.    ]
  [ 2.4442  0.7577  2.525  ...  2.8723 73.5611  1.    ]
  [ 2.3809  0.7617  2.5064 ...  3.0568 73.4842  1.    ]]

 [[ 2.3246  0.6223  2.0025 ...  2.7961 74.1924  0.    ]
  [ 2.4302  0.6224  2.0457 ...  2.8358 74.1295  0.    ]
  [ 2.5134  0.6223  2.0963 ...  2.8359 74.1919  0.    ]
  ...
  [ 2.3898  0.6279  2.048  ...  2.8005 73.9861  0.    ]
  [ 2.4245  0.6261  2.0422 ...  2.7474 74.0438  0.    ]
  [ 2.3849  0.6269  2.058  ...  2.8083 74.0438  0.    ]]]
(6691, 80, 16)
(6691, 80, 15)
train_out
(6691, 1)
test_out
(2974, 1)
vals_out
[[  99789.]
 [1467263.]
 [   9995.]
 ...
 [1294431.]
 [1294791.]
 [ 872419.]]
(2231, 1)
[[0.04943313]
 [0.73022468]
 [0.00472954]
 ...
 [0.64418095]
 [0.64436018]
 [0.43408394]]
(2231, 1)
(6691, 80, 15)
(2974, 80, 15)
(2231, 80, 15)
logs/fit/20231214-180516
Epoch 1/100
2023-12-14 18:05:18.800369: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600
2023-12-14 18:05:19.043419: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f22479f80d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-12-14 18:05:19.043473: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0
2023-12-14 18:05:19.049385: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-12-14 18:05:19.154812: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
210/210 - 6s - loss: 0.2537 - mse: 0.5082 - mae: 0.6377 - val_loss: 0.2564 - val_mse: 0.5258 - val_mae: 0.6402 - 6s/epoch - 30ms/step
Epoch 2/100
210/210 - 1s - loss: 0.2481 - mse: 0.4982 - mae: 0.6277 - val_loss: 0.2452 - val_mse: 0.4962 - val_mae: 0.6213 - 1s/epoch - 7ms/step
Epoch 3/100
210/210 - 1s - loss: 0.2098 - mse: 0.4246 - mae: 0.5596 - val_loss: 0.1632 - val_mse: 0.3292 - val_mae: 0.4776 - 1s/epoch - 6ms/step
Epoch 4/100
210/210 - 1s - loss: 0.1102 - mse: 0.2220 - mae: 0.3799 - val_loss: 0.0721 - val_mse: 0.1444 - val_mae: 0.3066 - 1s/epoch - 7ms/step
Epoch 5/100
210/210 - 1s - loss: 0.0597 - mse: 0.1194 - mae: 0.2761 - val_loss: 0.0548 - val_mse: 0.1095 - val_mae: 0.2684 - 1s/epoch - 6ms/step
Epoch 6/100
210/210 - 1s - loss: 0.0517 - mse: 0.1034 - mae: 0.2530 - val_loss: 0.0513 - val_mse: 0.1025 - val_mae: 0.2511 - 1s/epoch - 7ms/step
Epoch 7/100
210/210 - 1s - loss: 0.0493 - mse: 0.0987 - mae: 0.2442 - val_loss: 0.0495 - val_mse: 0.0990 - val_mae: 0.2438 - 1s/epoch - 7ms/step
Epoch 8/100
210/210 - 1s - loss: 0.0479 - mse: 0.0957 - mae: 0.2394 - val_loss: 0.0492 - val_mse: 0.0984 - val_mae: 0.2357 - 1s/epoch - 7ms/step
Epoch 9/100
210/210 - 1s - loss: 0.0462 - mse: 0.0925 - mae: 0.2349 - val_loss: 0.0467 - val_mse: 0.0933 - val_mae: 0.2336 - 1s/epoch - 7ms/step
Epoch 10/100
210/210 - 1s - loss: 0.0445 - mse: 0.0889 - mae: 0.2313 - val_loss: 0.0446 - val_mse: 0.0893 - val_mae: 0.2311 - 1s/epoch - 7ms/step
Epoch 11/100
210/210 - 1s - loss: 0.0424 - mse: 0.0848 - mae: 0.2274 - val_loss: 0.0428 - val_mse: 0.0855 - val_mae: 0.2312 - 1s/epoch - 7ms/step
Epoch 12/100
210/210 - 1s - loss: 0.0402 - mse: 0.0804 - mae: 0.2232 - val_loss: 0.0403 - val_mse: 0.0806 - val_mae: 0.2207 - 1s/epoch - 7ms/step
Epoch 13/100
210/210 - 1s - loss: 0.0379 - mse: 0.0758 - mae: 0.2184 - val_loss: 0.0371 - val_mse: 0.0743 - val_mae: 0.2166 - 1s/epoch - 7ms/step
Epoch 14/100
210/210 - 1s - loss: 0.0357 - mse: 0.0713 - mae: 0.2124 - val_loss: 0.0353 - val_mse: 0.0707 - val_mae: 0.2160 - 1s/epoch - 7ms/step
Epoch 15/100
210/210 - 1s - loss: 0.0336 - mse: 0.0672 - mae: 0.2063 - val_loss: 0.0347 - val_mse: 0.0694 - val_mae: 0.2177 - 1s/epoch - 7ms/step
Epoch 16/100
210/210 - 1s - loss: 0.0319 - mse: 0.0639 - mae: 0.2012 - val_loss: 0.0327 - val_mse: 0.0654 - val_mae: 0.2105 - 1s/epoch - 6ms/step
Epoch 17/100
210/210 - 1s - loss: 0.0303 - mse: 0.0606 - mae: 0.1957 - val_loss: 0.0296 - val_mse: 0.0592 - val_mae: 0.1931 - 1s/epoch - 6ms/step
Epoch 18/100
210/210 - 1s - loss: 0.0289 - mse: 0.0577 - mae: 0.1900 - val_loss: 0.0295 - val_mse: 0.0590 - val_mae: 0.1986 - 1s/epoch - 6ms/step
Epoch 19/100
210/210 - 1s - loss: 0.0276 - mse: 0.0553 - mae: 0.1850 - val_loss: 0.0267 - val_mse: 0.0534 - val_mae: 0.1832 - 1s/epoch - 7ms/step
Epoch 20/100
210/210 - 1s - loss: 0.0266 - mse: 0.0532 - mae: 0.1804 - val_loss: 0.0282 - val_mse: 0.0565 - val_mae: 0.1855 - 1s/epoch - 6ms/step
Epoch 21/100
210/210 - 1s - loss: 0.0257 - mse: 0.0513 - mae: 0.1775 - val_loss: 0.0270 - val_mse: 0.0541 - val_mae: 0.1888 - 1s/epoch - 7ms/step
Epoch 22/100
210/210 - 1s - loss: 0.0250 - mse: 0.0500 - mae: 0.1747 - val_loss: 0.0246 - val_mse: 0.0491 - val_mae: 0.1719 - 1s/epoch - 6ms/step
Epoch 23/100
210/210 - 1s - loss: 0.0244 - mse: 0.0488 - mae: 0.1716 - val_loss: 0.0238 - val_mse: 0.0476 - val_mae: 0.1738 - 1s/epoch - 7ms/step
Epoch 24/100
210/210 - 1s - loss: 0.0236 - mse: 0.0472 - mae: 0.1677 - val_loss: 0.0285 - val_mse: 0.0570 - val_mae: 0.1960 - 1s/epoch - 7ms/step
Epoch 25/100
210/210 - 1s - loss: 0.0230 - mse: 0.0461 - mae: 0.1658 - val_loss: 0.0221 - val_mse: 0.0441 - val_mae: 0.1616 - 1s/epoch - 6ms/step
Epoch 26/100
210/210 - 1s - loss: 0.0224 - mse: 0.0449 - mae: 0.1630 - val_loss: 0.0250 - val_mse: 0.0500 - val_mae: 0.1798 - 1s/epoch - 7ms/step
Epoch 27/100
210/210 - 1s - loss: 0.0218 - mse: 0.0435 - mae: 0.1607 - val_loss: 0.0228 - val_mse: 0.0456 - val_mae: 0.1625 - 1s/epoch - 6ms/step
Epoch 28/100
210/210 - 1s - loss: 0.0214 - mse: 0.0427 - mae: 0.1585 - val_loss: 0.0214 - val_mse: 0.0429 - val_mae: 0.1622 - 1s/epoch - 6ms/step
Epoch 29/100
210/210 - 1s - loss: 0.0211 - mse: 0.0421 - mae: 0.1564 - val_loss: 0.0221 - val_mse: 0.0442 - val_mae: 0.1667 - 1s/epoch - 6ms/step
Epoch 30/100
210/210 - 1s - loss: 0.0206 - mse: 0.0412 - mae: 0.1555 - val_loss: 0.0210 - val_mse: 0.0421 - val_mae: 0.1606 - 1s/epoch - 7ms/step
Epoch 31/100
210/210 - 1s - loss: 0.0203 - mse: 0.0406 - mae: 0.1538 - val_loss: 0.0203 - val_mse: 0.0405 - val_mae: 0.1570 - 1s/epoch - 7ms/step
Epoch 32/100
210/210 - 1s - loss: 0.0200 - mse: 0.0400 - mae: 0.1528 - val_loss: 0.0244 - val_mse: 0.0488 - val_mae: 0.1762 - 1s/epoch - 7ms/step
Epoch 33/100
210/210 - 1s - loss: 0.0197 - mse: 0.0394 - mae: 0.1512 - val_loss: 0.0228 - val_mse: 0.0455 - val_mae: 0.1694 - 1s/epoch - 6ms/step
Epoch 34/100
210/210 - 1s - loss: 0.0194 - mse: 0.0388 - mae: 0.1505 - val_loss: 0.0196 - val_mse: 0.0392 - val_mae: 0.1508 - 1s/epoch - 6ms/step
Epoch 35/100
210/210 - 1s - loss: 0.0193 - mse: 0.0387 - mae: 0.1490 - val_loss: 0.0195 - val_mse: 0.0390 - val_mae: 0.1533 - 1s/epoch - 7ms/step
Epoch 36/100
210/210 - 1s - loss: 0.0191 - mse: 0.0382 - mae: 0.1488 - val_loss: 0.0218 - val_mse: 0.0435 - val_mae: 0.1590 - 1s/epoch - 7ms/step
Epoch 37/100
210/210 - 1s - loss: 0.0189 - mse: 0.0378 - mae: 0.1472 - val_loss: 0.0193 - val_mse: 0.0386 - val_mae: 0.1490 - 1s/epoch - 7ms/step
Epoch 38/100
210/210 - 1s - loss: 0.0189 - mse: 0.0378 - mae: 0.1470 - val_loss: 0.0219 - val_mse: 0.0437 - val_mae: 0.1653 - 1s/epoch - 7ms/step
Epoch 39/100
210/210 - 1s - loss: 0.0187 - mse: 0.0374 - mae: 0.1467 - val_loss: 0.0224 - val_mse: 0.0448 - val_mae: 0.1611 - 1s/epoch - 7ms/step
Epoch 40/100
210/210 - 1s - loss: 0.0185 - mse: 0.0369 - mae: 0.1461 - val_loss: 0.0216 - val_mse: 0.0431 - val_mae: 0.1581 - 1s/epoch - 6ms/step
Epoch 41/100
210/210 - 1s - loss: 0.0184 - mse: 0.0368 - mae: 0.1451 - val_loss: 0.0236 - val_mse: 0.0472 - val_mae: 0.1730 - 1s/epoch - 7ms/step
Epoch 42/100
210/210 - 1s - loss: 0.0182 - mse: 0.0364 - mae: 0.1444 - val_loss: 0.0209 - val_mse: 0.0418 - val_mae: 0.1551 - 1s/epoch - 6ms/step
Epoch 43/100
210/210 - 1s - loss: 0.0182 - mse: 0.0364 - mae: 0.1444 - val_loss: 0.0214 - val_mse: 0.0427 - val_mae: 0.1630 - 1s/epoch - 6ms/step
Epoch 44/100
210/210 - 1s - loss: 0.0180 - mse: 0.0360 - mae: 0.1435 - val_loss: 0.0188 - val_mse: 0.0375 - val_mae: 0.1465 - 1s/epoch - 6ms/step
Epoch 45/100
210/210 - 1s - loss: 0.0179 - mse: 0.0357 - mae: 0.1427 - val_loss: 0.0179 - val_mse: 0.0358 - val_mae: 0.1441 - 1s/epoch - 6ms/step
Epoch 46/100
210/210 - 1s - loss: 0.0180 - mse: 0.0359 - mae: 0.1430 - val_loss: 0.0186 - val_mse: 0.0372 - val_mae: 0.1493 - 1s/epoch - 6ms/step
Epoch 47/100
210/210 - 1s - loss: 0.0177 - mse: 0.0354 - mae: 0.1423 - val_loss: 0.0198 - val_mse: 0.0397 - val_mae: 0.1553 - 1s/epoch - 6ms/step
Epoch 48/100
210/210 - 1s - loss: 0.0177 - mse: 0.0354 - mae: 0.1424 - val_loss: 0.0276 - val_mse: 0.0552 - val_mae: 0.1879 - 1s/epoch - 6ms/step
Epoch 49/100
210/210 - 1s - loss: 0.0177 - mse: 0.0354 - mae: 0.1416 - val_loss: 0.0178 - val_mse: 0.0357 - val_mae: 0.1438 - 1s/epoch - 6ms/step
Epoch 50/100
210/210 - 1s - loss: 0.0177 - mse: 0.0353 - mae: 0.1418 - val_loss: 0.0179 - val_mse: 0.0358 - val_mae: 0.1428 - 1s/epoch - 6ms/step
Epoch 51/100
210/210 - 1s - loss: 0.0174 - mse: 0.0349 - mae: 0.1408 - val_loss: 0.0228 - val_mse: 0.0457 - val_mae: 0.1684 - 1s/epoch - 6ms/step
Epoch 52/100
210/210 - 1s - loss: 0.0176 - mse: 0.0352 - mae: 0.1420 - val_loss: 0.0191 - val_mse: 0.0382 - val_mae: 0.1513 - 1s/epoch - 6ms/step
Epoch 53/100
210/210 - 1s - loss: 0.0175 - mse: 0.0349 - mae: 0.1413 - val_loss: 0.0188 - val_mse: 0.0375 - val_mae: 0.1457 - 1s/epoch - 6ms/step
Epoch 54/100
210/210 - 1s - loss: 0.0174 - mse: 0.0348 - mae: 0.1409 - val_loss: 0.0218 - val_mse: 0.0437 - val_mae: 0.1645 - 1s/epoch - 6ms/step
Epoch 55/100
Restoring model weights from the end of the best epoch: 45.
210/210 - 1s - loss: 0.0172 - mse: 0.0344 - mae: 0.1397 - val_loss: 0.0180 - val_mse: 0.0360 - val_mae: 0.1456 - 1s/epoch - 6ms/step
Epoch 55: early stopping
(2974, 80, 15)
 1/93 [..............................] - ETA: 28s25/93 [=======>......................] - ETA: 0s 48/93 [==============>...............] - ETA: 0s70/93 [=====================>........] - ETA: 0s92/93 [============================>.] - ETA: 0s93/93 [==============================] - ETA: 0s93/93 [==============================] - 1s 3ms/step
R^2: 0.6197003985388501
Mean Absolute Error (MAE): 0.14714596616350165
Mean Squared Error (MSE): 0.03737386971669148
Mean Absolute Percentage Error (MAPE): 438260506402.0428
Root Mean Squared Error (RMSE): 0.19332322601459836
Explained Variance Score: 0.6197004889851111
Max Error: 0.9574285966101221
Mean Squared Log Error: 0.017156138676897432
Median Absolute Error: 0.1141725125796198
